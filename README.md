# Audio-Processing-Tools-List (APTL)

This is a list of sound, audio processing tools which contains machine learning, audio signal processing, sound synthesis, spatial audio, music information retrieval, music generation, speech recognition, speech synthesis and more.

## Machine Learning (ML)

* [librosa](https://librosa.org/doc/latest/index.html)  Librosa is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems.
* [Essentia](http://essentia.upf.edu/)  Essentia is an open-source C++ library for audio analysis and audio-based music information retrieval released under the Affero GPLv3 license. It contains an extensive collection of reusable algorithms which implement audio input/output functionality, standard digital signal processing blocks, statistical characterization of data, and a large set of spectral, temporal, tonal and high-level music descriptors. C++ library for audio and music analysis, description and synthesis, including Python bindings.
* [DDSP](https://github.com/magenta/ddsp)  DDSP: Differentiable Digital Signal Processing. DDSP is a library of differentiable versions of common DSP functions (such as synthesizers, waveshapers, and filters). This allows these interpretable elements to be used as part of an deep learning model, especially as the output layers for audio generation.
* [aubio](https://aubio.org/)  aubio is a tool designed for the extraction of annotations from audio signals. Its features include segmenting a sound file before each of its attacks, performing pitch detection, tapping the beat and producing midi streams from live audio.
* [IPython](https://ipython.readthedocs.io/en/stable/index.html)  IPython provides a rich toolkit to help you make the most of using Python interactively.
* [torchaudio](https://github.com/pytorch/audio)  an audio library for PyTorch. Data manipulation and transformation for audio signal processing, powered by PyTorch.
* [Kapre](https://kapre.readthedocs.io/en/latest/#)  Kapre: Keras Audio Preprocessors. Keras Audio Preprocessors - compute STFT, InverseSTFT, Melspectrogram, and others on GPU real-time.
* [praudio](https://github.com/musikalkemist/praudio)  Audio preprocessing framework for Deep Learning audio applications.
* [DeepAFx](https://github.com/adobe-research/DeepAFx)  DeepAFx: Deep Audio Effects. Audio signal processing effects (FX) are used to manipulate sound characteristics across a variety of media. Many FX, however, can be difficult or tedious to use, particularly for novice users. In our work, we aim to simplify how audio FX are used by training a machine to use FX directly and perform automatic audio production tasks. By using familiar and existing tools for processing and suggesting control parameters, we can create a unique paradigm that blends the power of AI with human creative control to empower creators.
* [nnAudio](https://github.com/KinWaiCheuk/nnAudio)  nnAudio is an audio processing toolbox using PyTorch convolutional neural network as its backend. By doing so, spectrograms can be generated from audio on-the-fly during neural network training and the Fourier kernels (e.g. or CQT kernels) can be trained.
* [WavEncoder](https://github.com/shangeth/wavencoder)  WavEncoder is a Python library for encoding audio signals, transforms for audio augmentation, and training audio classification models with PyTorch backend.
* [SciPy](https://scipy.org/)  SciPy (pronounced "Sigh Pie") is an open-source software for mathematics, science, and engineering. It includes modules for statistics, optimization, integration, linear algebra, Fourier transforms, signal and image processing, ODE solvers, and more.
* [pyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis/)  Python Audio Analysis Library: Feature Extraction, Classification, Segmentation and Applications.
* [Mutagen](https://mutagen.readthedocs.io/en/latest/#)  Mutagen is a Python module to handle audio metadata. It supports ASF, FLAC, MP4, Monkey‚Äôs Audio, MP3, Musepack, Ogg Opus, Ogg FLAC, Ogg Speex, Ogg Theora, Ogg Vorbis, True Audio, WavPack, OptimFROG, and AIFF audio files. All versions of ID3v2 are supported, and all standard ID3v2.4 frames are parsed. It can read Xing headers to accurately calculate the bitrate and length of MP3s. ID3 and APEv2 tags can be edited regardless of audio format. It can also manipulate Ogg streams on an individual packet/page level.
* [LibXtract](https://github.com/jamiebullock/LibXtract)  LibXtract is a simple, portable, lightweight library of audio feature extraction functions. The purpose of the library is to provide a relatively exhaustive set of feature extraction primatives that are designed to be 'cascaded' to create a extraction hierarchies.
* [dejavu](https://github.com/worldveil/dejavu)  Audio fingerprinting and recognition in Python. Dejavu can memorize audio by listening to it once and fingerprinting it. Then by playing a song and recording microphone input or reading from disk, Dejavu attempts to match the audio against the fingerprints held in the database, returning the song being played.
* [Matchering](https://github.com/sergree/matchering)  üéöÔ∏è Open Source Audio Matching and Mastering. **[Matchering 2.0](https://github.com/sergree/matchering)** is a novel **[Containerized Web Application](https://github.com/sergree/matchering#docker-image---the-easiest-way)** and **[Python Library](https://pypi.org/project/matchering)** for audio matching and [mastering](https://en.wikipedia.org/wiki/Audio_mastering).
* [TimeSide](https://github.com/Parisson/TimeSide)  TimeSide is a python framework enabling low and high level audio analysis, imaging, transcoding, streaming and labelling. Its high-level API is designed to enable complex processing on very large datasets of any audio or video assets with a plug-in architecture, a secure scalable backend and an extensible dynamic web frontend.

## Audio Signal Processing (ASP)

* [SoundFile](https://pysoundfile.readthedocs.io/en/latest/)  SoundFile is an audio library based on libsndfile, CFFI and NumPy.
* [Audio DSPy](https://github.com/jatinchowdhury18/audio_dspy)  audio_dspy is a Python package for audio signal processing tools.
* [pyAudioDspTools](https://pyaudiodsptools.readthedocs.io/en/latest/#)  pyAudioDspTools is a python 3 package for manipulating audio by just using numpy.
* [wave](https://docs.python.org/3/library/wave.html)  The wave module provides a convenient interface to the WAV sound format. It does not support compression/decompression, but it does support mono/stereo.
* [PyAudio](https://people.csail.mit.edu/hubert/pyaudio/)  PyAudio provides [Python](http://www.python.org/) bindings for [PortAudio](http://www.portaudio.com/) v19, the cross-platform audio I/O library. With PyAudio, you can easily use Python to play and record audio on a variety of platforms, such as GNU/Linux, Microsoft Windows, and Apple macOS.
* [PortAudio](http://www.portaudio.com/)  PortAudio is a free, cross-platform, [open-source](http://www.portaudio.com/license.html), audio I/O library.  It lets you write simple audio programs in 'C' or C++ that will compile and run on many platforms including Windows, Macintosh OS X, and Unix (OSS/ALSA). It is intended to promote the exchange of audio software between developers on different platforms. Many [applications](http://www.portaudio.com/apps.html) use PortAudio for Audio I/O.
* [Pyo](https://github.com/belangeo/pyo)  pyo is a Python module written in C to help digital signal processing script creation.Python DSP module. With pyo, user will be able to include signal processing chains directly in Python scripts or projects, and to manipulate them in real time through the interpreter
* [tinytag](https://github.com/devsnd/tinytag)  tinytag is a library for reading music meta data of most common audio files in pure python. Read audio and music meta data and duration of MP3, OGG, OPUS, MP4, M4A, FLAC, WMA, Wave and AIFF files with python 2 or 3.
* [Friture](https://friture.org/)  **Friture** is an application to visualize and analyze live audio data in real-time. Friture displays audio data in several widgets, such as a scope, a spectrum analyzer, or a rolling 2D spectrogram.
* [sounddevice](https://pypi.org/project/sounddevice/)  This [Python](https://www.python.org/) module provides bindings for the [PortAudio](http://www.portaudio.com/) library and a few convenience functions to play and record [NumPy](https://numpy.org/) arrays containing audio signals.
* [Pydub](https://github.com/jiaaro/pydub)  Manipulate audio with a simple and easy high level interface.
* [TarsosDSP](https://github.com/JorenSix/TarsosDSP)  TarsosDSP is a Java library for audio processing. Its aim is to provide an easy-to-use interface to practical music processing algorithms implemented, as simply as possible, in pure Java and without any other external dependencies.
* [JUCE](https://github.com/juce-framework/JUCE)  JUCE is an open-source cross-platform C++ application framework for creating high quality desktop and mobile applications, including VST, VST3, AU, AUv3, AAX and LV2 audio plug-ins and plug-in hosts. JUCE can be easily integrated with existing projects via CMake, or can be used as a project generation tool via the [Projucer](https://juce.com/discover/projucer), which supports exporting projects for Xcode (macOS and iOS), Visual Studio, Android Studio, Code::Blocks and Linux Makefiles as well as containing a source code editor.
* [Q](https://cycfi.github.io/q/)  Q is a cross-platform C++ library for Audio Digital Signal Processing. Aptly named after the ‚ÄúQ factor‚Äù, a dimensionless parameter that describes the quality of a resonant circuit, the Q DSP Library is designed to be simple and elegant, as the simplicity of its name suggests, and efficient enough to run on small microcontrollers.
* [BasicDSP](https://github.com/trcwm/BasicDSP)  BasicDSP - A tool for processing audio / experimenting with signal processing.
* [Speech Signal Processing Toolkit (SPTK)](http://sp-tk.sourceforge.net/)  The Speech Signal Processing Toolkit (SPTK) is a suite of speech signal processing tools for UNIX environments, e.g., LPC analysis, PARCOR analysis, LSP analysis, PARCOR synthesis filter, LSP synthesis filter, vector quantization techniques, and other extended versions of them.
* [eDSP](https://mohabouje.github.io/edsp-docs/)  *eDSP* (easy Digital Signal Processing) is a digital signal processing framework written in modern C++ that implements some of the common functions and algorithms frequently used in digital signal processing, audio engineering & telecommunications systems.
* [KFR](https://www.kfrlib.com/)  KFR is an open source C++ DSP framework that focuses on high performance. Fast, modern C++ DSP framework, FFT, Sample Rate Conversion, FIR/IIR/Biquad Filters (SSE, AVX, AVX-512, ARM NEON).
* [MWEngine](https://github.com/igorski/MWEngine)  Audio engine and DSP for Android, written in C++ providing low latency performance within a musical context, while providing a Java/Kotlin API. Supports both OpenSL and AAudio.

## Sound Synthesis (SS)

* [Csound](https://csound.com/)  Csound is a sound and music computing system which was originally developed by Barry Vercoe in 1985 at MIT Media Lab. Since the 90s, it has been developed by a group of core developers.
* [Pure Data](https://puredata.info/)  **Pure Data** ( **Pd** ) is a [visual programming language](https://en.wikipedia.org/wiki/Visual_programming_language "Visual programming language") developed by [Miller Puckette](https://en.wikipedia.org/wiki/Miller_Puckette "Miller Puckette") in the 1990s for creating [interactive](https://en.wikipedia.org/wiki/Interaction "Interaction") [computer music](https://en.wikipedia.org/wiki/Computer_music "Computer music") and [multimedia](https://en.wikipedia.org/wiki/Multimedia "Multimedia") works. While Puckette is the main author of the program, Pd is an [open-source](https://en.wikipedia.org/wiki/Open-source_software "Open-source software") project with a large developer base working on new extensions. It is released under [BSD-3-Clause](https://en.wikipedia.org/wiki/BSD_licenses "BSD licenses"). It runs on [Linux](https://en.wikipedia.org/wiki/Linux "Linux"), [MacOS](https://en.wikipedia.org/wiki/MacOS "MacOS"), [iOS](https://en.wikipedia.org/wiki/IOS "IOS"), [Android](https://en.wikipedia.org/wiki/Android_(operating_system)) "Android (operating system)") and [Windows](https://en.wikipedia.org/wiki/Windows "Windows"). Ports exist for [FreeBSD](https://en.wikipedia.org/wiki/FreeBSD "FreeBSD") and [IRIX](https://en.wikipedia.org/wiki/IRIX "IRIX").
* [Max/MSP/Jitter](https://cycling74.com/)  **Max** , also known as Max/MSP/Jitter, is a [visual programming language](https://en.wikipedia.org/wiki/Visual_programming_language "Visual programming language") for [music](https://en.wikipedia.org/wiki/Music "Music") and [multimedia](https://en.wikipedia.org/wiki/Multimedia "Multimedia") developed and maintained by [San Francisco](https://en.wikipedia.org/wiki/San_Francisco "San Francisco")-based software company [Cycling &#39;74](https://en.wikipedia.org/wiki/Cycling_%2774 "Cycling '74"). Over its more than thirty-year history, it has been used by composers, performers, software designers, researchers, and artists to create recordings, performances, and installations.
* [Kyma (sound design language)](https://kyma.symbolicsound.com/)  **Kyma** is a visual programming language for sound design used by musicians, researchers, and sound designers. In Kyma, a user programs a multiprocessor DSP by graphically connecting modules on the screen of a [Macintosh](https://en.wikipedia.org/wiki/Macintosh "Macintosh") or [Windows](https://en.wikipedia.org/wiki/Microsoft_Windows "Microsoft Windows") computer.
* [SuperCollider](https://supercollider.github.io/)  **SuperCollider** is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. An audio server, programming language, and IDE for sound synthesis and algorithmic composition.
* [Sonic Pi](https://sonic-pi.net/)  **Sonic Pi** is a [live coding](https://en.wikipedia.org/wiki/Live_coding "Live coding") environment based on [Ruby](https://en.wikipedia.org/wiki/Ruby_(programming_language)) "Ruby (programming language)"), originally designed to support both computing and music lessons in schools, developed by Sam Aaron in the [University of Cambridge Computer Laboratory](https://en.wikipedia.org/wiki/Computer_Laboratory,_University_of_Cambridge "Computer Laboratory, University of Cambridge") in collaboration with [Raspberry Pi Foundation](https://en.wikipedia.org/wiki/Raspberry_Pi_Foundation "Raspberry Pi Foundation").
* [Reaktor](https://en.wikipedia.org/wiki/Reaktor)  **Reaktor** is a graphical [modular software music studio](https://en.wikipedia.org/wiki/Modular_software_music_studio "Modular software music studio") developed by [Native Instruments](https://en.wikipedia.org/wiki/Native_Instruments "Native Instruments") (NI). It allows musicians and sound specialists to design and build their own instruments, [samplers](https://en.wikipedia.org/wiki/Sampler_(musical_instrument)) "Sampler (musical instrument)"), effects and sound design tools. It is supplied with many ready-to-use instruments and effects, from emulations of classic [synthesizers](https://en.wikipedia.org/wiki/Synthesizer "Synthesizer") to futuristic sound design tools.
* [RTcmix](http://rtcmix.org/)  **RTcmix** is a real-time software "language" for doing digital sound synthesis and signal-processing. It is written in C/C++, and is distributed open-source, free of charge.
* [ChucK](https://chuck.stanford.edu/)  ChucK is a programming language for real-time sound synthesis and music creation. ChucK offers a unique time-based, concurrent programming model that is precise and expressive (we call this strongly-timed), dynamic control rates, and the ability to add and modify code on-the-fly. In addition, ChucK supports MIDI, OpenSoundControl, HID device, and multi-channel audio. It is open-source and freely available on MacOS X, Windows, and Linux. It's fun and easy to learn, and offers composers, researchers, and performers a powerful programming tool for building and experimenting with complex audio synthesis/analysis programs, and real-time interactive music.
* [Faust](https://faust.grame.fr/)  Faust (Functional Audio Stream) is a functional programming language for sound synthesis and audio processing with a strong focus on the design of synthesizers, musical instruments, audio effects, etc. Faust targets high-performance signal processing applications and audio plug-ins for a variety of platforms and standards.
* [SOUL](https://soul.dev/)  The SOUL programming language and API. SOUL (SOUnd Language) is an attempt to modernise and optimise the way high-performance, low-latency audio code is written and executed.
* [Sound2Synth](https://github.com/Sound2Synth/Sound2Synth)  Sound2Synth: Interpreting Sound via FM Synthesizer Parameters Estimation.
* [JSyn](http://www.softsynth.com/jsyn/)  JSyn is a modular audio synthesizer for Java by Phil Burk. JSyn allows you to [develop](http://www.softsynth.com/jsyn/developers/) interactive computer music programs in Java. It can be used to generate sound effects, audio environments, or music. JSyn is based on the traditional model of unit generators which can be connected together to form complex sounds.
* [pyo-tools](https://github.com/belangeo/pyo-tools)  Repository of ready-to-use python classes for building audio effects and synths with pyo.
* [AudioKit](https://github.com/AudioKit/AudioKit)  AudioKit is an audio synthesis, processing, and analysis platform for iOS, macOS (including Catalyst), and tvOS.
* [Twang](https://github.com/AldaronLau/twang)  Library for pure Rust advanced audio synthesis.
* [Gensound](https://github.com/Quefumas/gensound)  Pythonic audio processing and generation framework. The Python way to audio processing & synthesis.
* [OTTO](https://bitfieldaudio.com/)  The OTTO is a digital hardware groovebox, with synths, samplers, effects and a sequencer with an audio looper. The interface is flat, modular and easy to use, but most of all, it aims to encourage experimentation.
* [Loris](https://github.com/tractal/loris)  Loris is a library for sound analysis, synthesis, and morphing, developed by Kelly Fitz and Lippold Haken at the CERL Sound Group. Loris includes a C++ class library, Python module, C-linkable interface, command line utilities, and documentation.

## Spatial Audio (SA)

* [spaudiopy](https://spaudiopy.readthedocs.io/en/latest/index.html)  Spatial Audio Python Package. The focus (so far) is on spatial audio encoders and decoders. The package includes e.g. spherical harmonics processing and (binaural renderings of) loudspeaker decoders, such as VBAP and AllRAD.
* [Spatial_Audio_Framework (SAF)](https://leomccormack.github.io/Spatial_Audio_Framework/)  The Spatial_Audio_Framework (SAF) is an open-source and cross-platform framework for developing spatial audio related algorithms and software in C/C++. Originally intended as a resource for researchers in the field, the framework has gradually grown into a rather large and well-documented codebase comprising a number of distinct [**modules**](https://github.com/leomccormack/Spatial_Audio_Framework/blob/master/framework/modules); with each module targeting a specific sub-field of spatial audio (e.g. Ambisonics encoding/decoding, spherical array processing, amplitude-panning, HRIR processing, room simulation, etc.).
* [HO-SIRR](https://github.com/leomccormack/HO-SIRR)  Higher-order Spatial Impulse Response Rendering (HO-SIRR) is a rendering method, which can synthesise output loudspeaker array room impulse responses (RIRs) using input spherical harmonic (Ambisonic/B-Format) RIRs of arbitrary order. A MATLAB implementation of the Higher-order Spatial Impulse Response Rendering (HO-SIRR) algorithm; an alternative approach for reproducing Ambisonic RIRs over loudspeakers.
* [SpatGRIS](https://github.com/GRIS-UdeM/SpatGRIS)  SpatGRIS is a sound spatialization software that frees composers and sound designers from the constraints of real-world speaker setups. With the ControlGRIS plugin distributed with SpatGRIS, rich spatial trajectories can be composed directly in your DAW and reproduced in real-time on any speaker layout. It is fast, stable, cross-platform, easy to learn and works with the tools you already know. SpatGRIS supports any speaker setup, including 2D layouts like quad, 5.1 or octophonic rings, and 3D layouts like speaker domes, concert halls, theatres, etc. Projects can also be mixed down to stereo using a binaural head-related transfer function or simple stereo panning.
* [libmysofa](https://github.com/hoene/libmysofa)  Reader for AES SOFA files to get better HRTFs.

## Web Audio Processing (WAP)

* [WebRTC Audio Processing](https://github.com/xiongyihui/python-webrtc-audio-processing)  Python binding of WebRTC Audio Processing.
* [MIDI.js](https://galactic.ink/midi-js/)  üéπ Making life easy to create a MIDI-app on the web. Includes a library to program synesthesia into your app for memory recognition or for creating trippy effects. Convert soundfonts for Guitar, Bass, Drums, ect. into code that can be read by the browser. **[MIDI.js](https://github.com/mudcube/MIDI.js)** ties together, and builds upon frameworks that bring MIDI to the browser. Combine it with [jasmid](https://github.com/gasman/jasmid) to create a web-radio MIDI stream similar to this demo, or with [Three.js](https://github.com/mrdoob/three.js/), [Sparks.js](https://github.com/zz85/sparks.js/), or [GLSL](http://glslsandbox.com/) to create Audio/visual experiments.
* [Web Voice Processor](https://github.com/Picovoice/web-voice-processor)  A library for real-time voice processing in web browsers.
* [Tone.js](https://tonejs.github.io/)  Tone.js is a Web Audio framework for creating interactive music in the browser. The architecture of Tone.js aims to be familiar to both musicians and audio programmers creating web-based audio applications. On the high-level, Tone offers common DAW (digital audio workstation) features like a global transport for synchronizing and scheduling events as well as prebuilt synths and effects. Additionally, Tone provides high-performance building blocks to create your own synthesizers, effects, and complex control signals.

## Music Information Retrieval (MIR)

* [Madmom](https://madmom.readthedocs.io/en/latest/index.html)  Madmom is an audio signal processing library written in Python with a strong focus on music information retrieval (MIR) tasks.
* [Beets](https://beets.io/)  Beets is the media library management system for obsessive music geeks. music library manager and MusicBrainz tagger.

## Music Generation (MG)

* [isobar](https://github.com/ideoforms/isobar)  isobar is a Python library for creating and manipulating musical patterns, designed for use in algorithmic composition, generative music and sonification. It makes it quick and easy to express complex musical ideas, and can send and receive events from various different sources including MIDI, MIDI files, and OSC.
* [MusPy](https://salu133445.github.io/muspy/)  MusPy is an open source Python library for symbolic music generation. It provides essential tools for developing a music generation system, including dataset management, data I/O, data preprocessing and model evaluation.
* [music21](https://web.mit.edu/music21/)  music21 is a Toolkit for Computational Musicology.
* [Mozart](https://github.com/aashrafh/Mozart)  An optical music recognition (OMR) system. Converts sheet music to a machine-readable version. The aim of this project is to develop a sheet music reader. This is called Optical Music Recognition (OMR). Its objective is to convert sheet music to a machine-readable version. We take a simplified version where we convert an image of sheet music to a textual representation that can be further processed to produce midi files or audio files like wav or mp3.
* [MidiTok](https://github.com/Natooz/MidiTok)  A convenient MIDI / symbolic music tokenizer for Deep Learning networks, with multiple strategies .üé∂
* [SCAMP](http://scamp.marcevanstein.com/#)  SCAMP is an computer-assisted composition framework in Python designed to act as a hub, flexibly connecting the composer-programmer to a wide variety of resources for playback and notation. SCAMP allows the user to manage the flow of musical time, play notes either using [FluidSynth](http://www.fluidsynth.org/) or via MIDI or OSC messages to an external synthesizer, and ultimately quantize and export the result to music notation in the form of MusicXML or Lilypond. Overall, the framework aims to address pervasive technical challenges while imposing as little as possible on the aesthetic choices of the composer-programmer.
* [Facet](https://github.com/mjcella/facet)  Facet is an open-source live coding system for algorithmic music. With a code editor in the browser and a NodeJS server running locally on your machine, Facet can generate and sequence audio and MIDI data in real-time.Facet is a live coding system for algorithmic music.
* [Mingus](https://github.com/bspaans/python-mingus)  Mingus is a music package for Python. Mingus is a package for Python used by programmers, musicians, composers and researchers to make and analyse music.
* [Audeo](http://faculty.washington.edu/shlizee/audeo/)  ***Audeo*** is a novel system that gets as an input video frames of a musician playing the piano and generates the music for that video. Generation of music from visual cues is a challenging problem and it is not clear whether it is an attainable goal at all. Our main aim in this work is to explore the plausibility of such a transformation and to identify cues and components able to carry the association of sounds with visual events. To achieve the transformation we built a full pipeline named *Audeo* containing three components. We first translate the video frames of the keyboard and the musician hand movements into raw mechanical musical symbolic representation Piano-Roll (Roll) for each video frame which represents the keys pressed at each time step. We then adapt the Roll to be amenable for audio synthesis by including temporal correlations. This step turns out to be critical for meaningful audio generation. As a last step, we implement Midi synthesizers to generate realistic music. *Audeo* converts video to audio smoothly and clearly with only a few setup constraints.

## Speech Recognition (ASR)

* [Kaldi](http://kaldi-asr.org/)  Kaldi is a toolkit for speech recognition, intended for use by speech recognition researchers and professionals.
* [PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech)  Easy-to-use Speech Toolkit including SOTA/Streaming ASR with punctuation, influential TTS with text frontend, Speaker Verification System, End-to-End Speech Translation and Keyword Spotting.
* [Julius](https://github.com/julius-speech/julius)  Open-Source Large Vocabulary Continuous Speech Recognition Engine. "Julius" is a high-performance, small-footprint large vocabulary continuous speech recognition (LVCSR) decoder software for speech-related researchers and developers. The main platform is Linux and other Unix-based system, as well as Windows, Mac, Androids and other platforms.
* [audino](https://github.com/midas-research/audino)  audino is an open source audio annotation tool. It provides features such as transcription and labeling which enables annotation for Voice Activity Detection (VAD), Diarization, Speaker Identification, Automated Speech Recognition, Emotion Recognition tasks and more.
* [Wenet](https://wenet.org.cn/wenet/)  Wenet is an tansformer-based end-to-end ASR toolkit.
* [WaveNet](https://github.com/ibab/tensorflow-wavenet)  A TensorFlow implementation of DeepMind's WaveNet paper. The WaveNet neural network architecture directly generates a raw audio waveform, showing excellent results in text-to-speech and general audio generation (see the DeepMind blog post and paper for details).

## Speech Synthesis (TTS)

* [VITS](https://github.com/jaywalnut310/vits)  VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech. Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text.
* [NeuralSpeech](https://github.com/microsoft/NeuralSpeech)  **NeuralSpeech** is a research project in Microsoft Research Asia focusing on neural network based speech processing, including automatic speech recognition (ASR), text to speech (TTS), etc.
* [Real-Time Voice Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)  Clone a voice in 5 seconds to generate arbitrary speech in real-time.  This repository is an implementation of [Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://arxiv.org/pdf/1806.04558.pdf) (SV2TTS) with a vocoder that works in real-time. SV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.
* [FastSpeech 2](https://github.com/ming024/FastSpeech2)  An implementation of Microsoft's "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech".
* [MelGAN](http://swpark.me/melgan/)  Generative Adversarial Networks for Conditional Waveform Synthesis.
* [HiFi-GAN](https://github.com/jik876/hifi-gan)  HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.

## And more
